{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df34aac6",
   "metadata": {},
   "source": [
    "# FIRST INSTALL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fc3a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\beulah\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\beulah\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abe722",
   "metadata": {},
   "source": [
    "# IMPORT REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb72079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5eea4",
   "metadata": {},
   "source": [
    "# Q1). Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294975d",
   "metadata": {},
   "source": [
    "# Sending get request to the webpage server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e832ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the source code of the page\n",
    "\n",
    "url = 'https://en.wikipedia.org'\n",
    "\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bfdd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the h1, h2, h3, h4, h5, h6 :\n",
      "\n",
      "h1 Main Page\n",
      "h1 Welcome to Wikipedia\n",
      "h2 From today's featured article\n",
      "h2 Did you know ...\n",
      "h2 In the news\n",
      "h2 On this day\n",
      "h2 Today's featured picture\n",
      "h2 Other areas of Wikipedia\n",
      "h2 Wikipedia's sister projects\n",
      "h2 Wikipedia languages\n",
      "h2 Navigation menu\n",
      "h3 Personal tools\n",
      "h3 Namespaces\n",
      "h3 Views\n",
      "h3 Search\n",
      "h3 Navigation\n",
      "h3 Contribute\n",
      "h3 Tools\n",
      "h3 Print/export\n",
      "h3 In other projects\n",
      "h3 Languages\n"
     ]
    }
   ],
   "source": [
    "titles = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "\n",
    "print(\"List of all the h1, h2, h3, h4, h5, h6 :\\n\")\n",
    "for heading in titles:\n",
    "    print(heading.name + ' ' + heading.text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfc5aa",
   "metadata": {},
   "source": [
    "# Q2). Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8b9b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating'\n",
    "\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b59c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a4f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100movie_name = [ ]\n",
    "year = [ ]\n",
    "movie_rating = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f46b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100movie_data = soup.find_all('div', class_='lister-item mode-advanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58cc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top100movie_data:\n",
    "    name = i.h3.a.text\n",
    "    top100movie_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b89e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top100movie_data:\n",
    "    year_of_release = i.h3.find('span', class_='lister-item-year').text.replace('(',\"\").replace(')',\"\")\n",
    "    year.append(year_of_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1251c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top100movie_data:\n",
    "    mr = i.find('div', class_='inline-block ratings-imdb-rating').text.replace('\\n',\"\")\n",
    "    movie_rating.append(mr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71a21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Movie_Name':top100movie_name,\n",
    "                    'Year_of_Release':year,\n",
    "                    'Rating':movie_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ea8eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kantara</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Movie_Name Year_of_Release Rating\n",
       "0                       The Shawshank Redemption            1994    9.3\n",
       "1                                        Kantara            2022    9.2\n",
       "2                                  The Godfather            1972    9.2\n",
       "3                                The Dark Knight            2008    9.0\n",
       "4  The Lord of the Rings: The Return of the King            2003    9.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533285c6",
   "metadata": {},
   "source": [
    "# Q3). Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2c3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/list/ls056092300/?sort=user_rating,desc&st_dt=&mode=detail&page=1'\n",
    "\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc2f0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiantop100movie_name = [ ]\n",
    "released_year = [ ]\n",
    "movie_rating = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7283416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiantop100movie_data = soup.find_all('div', class_='lister-item mode-detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indiantop100movie_data:\n",
    "    name = i.h3.a.text\n",
    "    indiantop100movie_name.append(name)\n",
    "    \n",
    "   \n",
    "    year_of_release = i.h3.find('span', class_='lister-item-year').text.replace('(',\"\").replace(')',\"\")\n",
    "    released_year.append(year_of_release)\n",
    "    \n",
    "    mr = i.find('span', class_='ipl-rating-star__rating').text.replace('\\n',\"\")\n",
    "    #print(mr)\n",
    "    movie_rating.append(mr)\n",
    "    #print(movie_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fc5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Movie_Name':indiantop100movie_name,\n",
    "                    'Year_of_Release':released_year,\n",
    "                    'Rating':movie_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7585062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sagara Sangamam</td>\n",
       "      <td>1983</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goopy Gyne Bagha Byne</td>\n",
       "      <td>1969</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pushpaka Vimana</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Movie_Name Year_of_Release Rating\n",
       "0        Sagara Sangamam            1983    8.8\n",
       "1  Goopy Gyne Bagha Byne            1969    8.7\n",
       "2                Nayakan            1987    8.6\n",
       "3        Pushpaka Vimana            1987    8.6\n",
       "4            Apur Sansar            1959    8.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41e05f",
   "metadata": {},
   "source": [
    "# Q4). Write a python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488998f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "\n",
    "response = requests.get(url)\n",
    "htmlcontent = response.content\n",
    "\n",
    "soup = BeautifulSoup(htmlcontent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba2c301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "former_president_names = [ ]\n",
    "office_term = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65074a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "president_list = soup.find_all('div', class_='presidentListing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a1674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in president_list:\n",
    "    names = i.h3.text\n",
    "    #print(names)\n",
    "    former_president_names.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26651aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25 July, 2017 to 25 July, 2022 \n",
      " 25 July, 2012 to 25 July, 2017 \n",
      " 25 July, 2007 to 25 July, 2012 \n",
      " 25 July, 2002 to 25 July, 2007 \n",
      " 25 July, 1997 to 25 July, 2002 \n",
      " 25 July, 1992 to 25 July, 1997 \n",
      " 25 July, 1987 to 25 July, 1992 \n",
      " 25 July, 1982 to 25 July, 1987 \n",
      " 25 July, 1977 to 25 July, 1982 \n",
      " 24 August, 1974 to 11 February, 1977\n",
      " 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974\n",
      " 13 May, 1967 to 3 May, 1969\n",
      " 13 May, 1962 to 13 May, 1967\n",
      " 26 January, 1950 to 13 May, 1962\n"
     ]
    }
   ],
   "source": [
    "for i in president_list:\n",
    "    ot = i.find('p').text.replace('Term of Office:','')\n",
    "    print(ot)\n",
    "    office_term.append(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635a9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                 Term  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name':former_president_names,\n",
    "                 'Term':office_term})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c7a5758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Term'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ece58",
   "metadata": {},
   "source": [
    "# Q7). Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :i) Headlineii) Timeiii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b61dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import date\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "d = today.strftime(\"%m-%d-%y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c21d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todays date: 10-29-22\n"
     ]
    }
   ],
   "source": [
    "print(\"Todays date:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0320976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnbc_url=\"https://www.cnbc.com/world/?region=world\".format(d)\n",
    "r = requests.get(cnbc_url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3295e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline : Big Tech falters on dreary earnings and forecasts — Meta has worst week ever, Amazon tumbles 13%\n",
      "Headline : Latest News\n",
      "Headline : QUOTE FINDER\n",
      "Headline : Markets\n",
      "Headline : Market MOVERS\n",
      "Headline : Most Active\n",
      "Headline : Unusual Volume\n",
      "Headline : Latest Market News\n",
      "Headline : Special Reports\n",
      "Headline : Trending Now\n",
      "Headline : Pro News and Analysis\n",
      "Headline : Sustainable Future\n",
      "Headline : Coronavirus\n",
      "Headline : CNBC Travel\n",
      "Headline : Make It\n",
      "Headline : Investing in supertrends\n",
      "Headline : News Tips\n",
      "Headline : Advertise With Us\n",
      "Headline : CNBC Newsletters\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.content)\n",
    "titles = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "for link in titles:\n",
    "    print(\"Headline : {}\".format(link.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d54cb59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 10-29-22\n",
      "Time: 19:22:42\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now() # current date and time\n",
    "\n",
    "#year = now.strftime(\"%Y\")\n",
    "#print(\"year:\", year)\n",
    "\n",
    "#month = now.strftime(\"%m\")\n",
    "#print(\"month:\", month)\n",
    "\n",
    "#day = now.strftime(\"%d\")\n",
    "#print(\"day:\", day)\n",
    "\n",
    "d = now.strftime(\"%m-%d-%y\")\n",
    "time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Day:\", d)\n",
    "print(\"Time:\", time)\n",
    "\n",
    "#date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "#print(\"date and time:\",date_time)\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67701681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2022/10/28/gm-temporarily-suspends-advertising-on-twitter-following-elon-musk-takeover.html',\n",
       " 'https://www.cnbc.com/2022/10/28/house-speaker-pelosi-husband-assaulted-at-home-assailant-arrested.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/10/29/philippines-death-toll-from-tropical-storm-nalgae-climbs-to-72.html',\n",
       " 'https://www.cnbc.com/2022/10/28/russia-ukraine-live-updates.html',\n",
       " 'https://www.cnbc.com/2022/10/28/imf-asia-would-have-most-to-lose-if-economic-fragmentation-worsens.html',\n",
       " 'https://www.cnbc.com/2022/10/28/sunak-is-almost-a-billionaire-with-a-net-worth-double-king-charles.html',\n",
       " 'https://www.cnbc.com/2022/10/29/us-says-north-korea-policy-unchanged-after-nuclear-remark-raises-eyebrows.html',\n",
       " 'https://www.cnbc.com/2022/10/28/musk-first-day-owning-twitter-leads-to-havoc-and-possible-hoax-.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/10/28/pce-inflation-september-2022-.html',\n",
       " 'https://www.cnbc.com/2022/10/28/musk-plans-twitter-content-moderation-council-as-questions-about-trump-return-loom.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/10/28/pending-home-sales-fell-10percent-in-september-from-august.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/10/28/eu-official-warns-musk-hell-have-to-fly-by-our-rules-as-he-buys-twitter.html',\n",
       " 'https://www.cnbc.com/2022/10/28/energy-crisis-europe-gas-prices-drop-but-could-rise-in-coming-months.html',\n",
       " 'https://www.cnbc.com/2022/10/28/europe-telco-industry-pushes-big-tech-to-pay-for-building-the-internet.html']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_links = []\n",
    "for nl in soup.find_all('div', class_=\"RiverPlusCard-container\"):\n",
    "    news_links.append(nl.a['href'])\n",
    "#news.a['href'])RiverPlusCard-container\n",
    "#RiverPlusCard-container\n",
    "#Home Page International PageBuilder-page\n",
    "news_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce001731",
   "metadata": {},
   "source": [
    "# Q8). Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details : i) Paper Title ii) Authors iii) Published Date iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "943324b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page\n",
    "\n",
    "Books=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e34b8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Title\n",
    "#Title=Books.find('h2')\n",
    "#Title\n",
    "#Title.text\n",
    "\n",
    "Title=[]\n",
    "for i in Books.find_all('h2'):\n",
    "    Title.append(i.text)\n",
    "#Title\n",
    "\n",
    "Author=[]\n",
    "for i in Books.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    Author.append(i.text)\n",
    "    \n",
    "Date=[]\n",
    "for i in Books.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    Date.append(i.text)\n",
    "#Date\n",
    "\n",
    "paperurl_links = []\n",
    "for pul in Books.find_all('a', class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    paperurl_links.append(pul['href'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66a391c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Title\":Title, \"Author\":Author, \"Published Date\":Date, \"Paper URL\":paperurl_links})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdcfb0",
   "metadata": {},
   "source": [
    "# Q9). Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "840b0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7935567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle BarbequeConnaught Place, Central Delhi',\n",
       " 'Jungle Jamboree3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Castle BarbequePacific Mall,Tagore Garden, West Delhi',\n",
       " 'Cafe KnoshThe Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'The Barbeque CompanyGardens Galleria,Sector 38A, Noida',\n",
       " 'India GrillHilton Garden Inn,Saket, South Delhi',\n",
       " 'Delhi BarbequeTaurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'The Monarch - Bar Be Que VillageIndirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Indian Grill RoomSuncity Business Tower,Golf Course Road, Gurgaon']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    names.append(i.text)\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3ff815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    locations.append(i.text)\n",
    "    \n",
    "locations\n",
    "\n",
    "price = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text.split('|')[0])\n",
    "    \n",
    "price\n",
    "\n",
    "ratings= []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "\n",
    "ratings\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n",
    "    \n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a5c8cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Images_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>₹ 1,680 for 2 (approx)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>₹ 1,700 for 2 (approx)</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Names  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2  Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "\n",
       "                                           Locations                    Price  \\\n",
       "0                     Connaught Place, Central Delhi  ₹ 2,000 for 2 (approx)    \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi  ₹ 1,680 for 2 (approx)    \n",
       "2             Pacific Mall,Tagore Garden, West Delhi  ₹ 2,000 for 2 (approx)    \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...  ₹ 3,000 for 2 (approx)    \n",
       "4                 Gardens Galleria,Sector 38A, Noida  ₹ 1,700 for 2 (approx)    \n",
       "5               Hilton Garden Inn,Saket, South Delhi  ₹ 2,400 for 2 (approx)    \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi  ₹ 1,800 for 2 (approx)    \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad  ₹ 1,900 for 2 (approx)    \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon  ₹ 2,200 for 2 (approx)    \n",
       "\n",
       "  Rating                                         Images_url  \n",
       "0    4.1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1    3.9  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2    3.9  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3    4.3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4      4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5    3.9  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6    3.6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7    3.8  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8    4.3  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Names':names,'Locations':locations,'Price':price,\n",
    "                   'Rating':ratings,'Images_url':images})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f92b7b",
   "metadata": {},
   "source": [
    "# Q10). Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en i) Rank ii) Publication iii) h5-index iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "697a15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "soup = BeautifulSoup(response.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbf825a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = []\n",
    "publication = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11fa5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('td', class_='gsc_mvt_p'):\n",
    "    \n",
    "    rank.append(i.text)\n",
    "#rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06a47782",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('td',class_='gsc_mvt_t'):\n",
    "    publication.append(i.text)\n",
    "#publication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a46d2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5index=[]\n",
    "for i in soup.find_all('a',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5index.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e86d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5median=[]\n",
    "for i in soup.find_all('span',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5median.append(i.text)\n",
    "#h5median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "444ff931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Rank':rank,\n",
    "                    'Publication':publication,\n",
    "                    'h5-index':h5index,\n",
    "                    'h5-median':h5median\n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e28852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
