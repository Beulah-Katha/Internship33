{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6e9fd3",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e93cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa76196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required libraries\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055612a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ebdb429",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product from www.amazon.in. \n",
    "The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search \n",
    "for guitars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First connect to webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Maximizing the automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart website\n",
    "\n",
    "url = 'https://www.amazon.in'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c53209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for sneakers \n",
    "\n",
    "#search_sneakers = driver.find_element(By.CLASS_NAME,\"nav-search-field\").text\n",
    "#search_sneakers.send_keys(\"sneakers\")\n",
    "\n",
    "print(\"Enter the product to search\")\n",
    "srch_word = input()\n",
    "\n",
    "#print(srch_word)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#/html/body/div[1]/div[1]/div/div[2]/form/input\n",
    "elem = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')  # Find the search box\n",
    "elem.send_keys(srch_word + Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca5e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f2f6b56",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. \n",
    "\n",
    "In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fetch the product information\n",
    "\n",
    "brand_name_url = []\n",
    "\n",
    "for page in range(0,3): \n",
    "    brand_tag = driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "\n",
    "    for i in brand_tag:    \n",
    "        brand_name_url.append(i.get_attribute('href'))\n",
    "        \n",
    "    next_button = driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[1]/div/span[1]/div[1]/div[68]/div/div/span/a[3]')\n",
    "#    next_button.click()\n",
    "#    time.sleep(3)\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ca333",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brand_name_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    next_button.click()\n",
    "brand_name_url[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\",\n",
    "#\"Availability\" and “Product URL”\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "brand_names = []\n",
    "prod_names = []\n",
    "price = []\n",
    "ret_exch = []\n",
    "expctd_delvry = []\n",
    "availability = [] \n",
    "prod_url = []\n",
    "\n",
    "for i  in brand_name_url[0:5]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        prod_url.append(i)\n",
    "        \n",
    "        names = driver.find_element(By.XPATH,'//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        brand_names.append(names.text.split(\" \")[0])\n",
    "        \n",
    "#        prod_names.append(names.text)\n",
    "        \n",
    "        p_names = driver.find_element(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "        price.append(p_names.text)\n",
    "        \n",
    "        re = driver.find_element(By.XPATH,'//a[@class=\"a-size-small a-link-normal a-text-normal\"]')\n",
    "        ret_exch.append(re.text)\n",
    "        \n",
    "        ed = driver.find_element(By.XPATH,'//span[@class=\"a-text-bold\"]')\n",
    "        expctd_delvry.append(ed.text)\n",
    "        \n",
    "        av = driver.find_element(By.XPATH,'//span[@class=\"a-size-base a-color-success\"]')\n",
    "        availability.append(av.text)\n",
    "        \n",
    "#        prod_url.append(i)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        brand_names.append('-')\n",
    "        prod_names.append('-')\n",
    "        price.append('-')\n",
    "        ret_exch.append('-')\n",
    "        expctd_delvry.append('-')\n",
    "        availability.append('-')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e14c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prod_url),len(brand_names),len(prod_names),len(price),len(ret_exch),len(expctd_delvry),len(availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40720a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c22562",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_exch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expctd_delvry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0620a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409fff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37885f8",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fea6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Maximizing the automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://images.google.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter data in element skill\n",
    "\n",
    "keyword = driver.find_element(By.XPATH,'//input[@class=\"gLFyf\"]')\n",
    "keyword.send_keys(\"fruits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking using absolute XPATH function\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "#print(len(images))\n",
    "\n",
    "img_urls = []\n",
    "\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    source= image.get_attribute('src')\n",
    "#    print(source)\n",
    "    if source is not None:\n",
    "\n",
    "        if(source[0:4] == 'http'):\n",
    "\n",
    "            img_urls.append(source)\n",
    "            \n",
    "\n",
    "len(img_urls)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ad142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "\n",
    "for i in img_urls:\n",
    "    print(i)\n",
    "#    images.append(img_urls.content)\n",
    "    images = requests.get(i)\n",
    "    images.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0076af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a634c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a37dcadb",
   "metadata": {},
   "source": [
    "images_data=[]\n",
    "\n",
    "for im in images_url:\n",
    "    images_data = requests.get(images_url).content\n",
    "#    print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee243aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bf0bb",
   "metadata": {},
   "source": [
    "# 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. \n",
    "Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148793b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "url = 'http://www.flipkart.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12471788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter data in element location\n",
    "\n",
    "item = driver.find_element(By.CLASS_NAME,'_3704LK' )\n",
    "item.send_keys(\"smartphone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f81d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking using absolute XPATH function\n",
    "\n",
    "search_button = driver.find_element(By.CLASS_NAME,'_34RNph')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand Name”, “Smartphone name”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_url = []\n",
    "\n",
    "prod_tag = driver.find_elements(By.XPATH,'//div[@class=\"_4rR01T\"]')\n",
    "\n",
    "\n",
    "for i in prod_tag[0:3]:\n",
    "    prod_url.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prod_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c331a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i  in prod_tag[0:3]:\n",
    "   \n",
    "        prod_url.append(i)\n",
    "        \n",
    "        names = driver.find_element(By.XPATH,'//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        brand_names.append(names.text.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa3700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850d34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7fff9c6",
   "metadata": {},
   "source": [
    "# 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188472f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7298941",
   "metadata": {},
   "source": [
    "# 6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36861d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d41f2149",
   "metadata": {},
   "source": [
    "# 7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bc889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d16f45",
   "metadata": {},
   "source": [
    "# 8. Write a python program to scrape the details for all billionaires from www.forbes.com. \n",
    "Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad41fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Maximizing the automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af37ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.forbes.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10dd97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "btn = driver.find_element(By.XPATH,'//div[@class=\"_69hVhdY4\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c632ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpBfVZz3mpBfVZz3\n",
    "bbtn = driver.find_element(By.XPATH,'//div[@class=\"mpBfVZz3\"]')\n",
    "bbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9d749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abbtn = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div/div/div[2]/ul/li[1]/div[2]/div[3]/ul/li[1]/a')\n",
    "abbtn.click()                            \n",
    "\n",
    "\n",
    "#/html/body/div[1]/main/div/section/section[1]/div/div/div[1]/div/div[1]/div[1]/div[2]/a/h2\n",
    "                            \n",
    "#/html/body/div[1]/main/div/section/section[1]/div/div/div[1]/div/div[1]/div[2]/div[2]/a/h2                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0636ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank active-sort\n",
    "rank_columns = driver.find_elements(By.XPATH,'//div[@class=\"rank\"]')\n",
    "names_columns = driver.find_elements(By.XPATH,'//div[@class=\"personName\"]')\n",
    "networth_columns = driver.find_elements(By.XPATH,'//div[@class=\"netWorth\"]')\n",
    "age_columns = driver.find_elements(By.XPATH,'//div[@class=\"age\"]')\n",
    "citizenship_columns = driver.find_elements(By.XPATH,'//div[@class=\"countryOfCitizenship\"]')\n",
    "source_columns = driver.find_elements(By.XPATH,'//div[@class=\"source\"]')\n",
    "industry_columns = driver.find_elements(By.XPATH,'//div[@class=\"category\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb96a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank_columns),len(names_columns),len(networth_columns),len(age_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d9cca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(citizenship_columns),len(source_columns),len(industry_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f22a0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "names = []\n",
    "networth = []\n",
    "ages = []\n",
    "citizenship = []\n",
    "source = []\n",
    "industry = []\n",
    "\n",
    "\n",
    "for c1 in rank_columns[0:9]:\n",
    "    ranks.append(c1.text)\n",
    "    \n",
    "for c2 in names_columns[0:9]:\n",
    "    names.append(c2.text)\n",
    "\n",
    "for c3 in networth_columns[0:9]:\n",
    "    networth.append(c3.text)\n",
    "    \n",
    "for c4 in age_columns[0:9]:\n",
    "    \n",
    "    ages.append(c4.text)\n",
    "    \n",
    "    \n",
    "for c5 in citizenship_columns[0:9]:\n",
    "    citizenship.append(c5.text)\n",
    "    \n",
    "for c6 in source_columns[0:9]:\n",
    "    source.append(c6.text)\n",
    "    \n",
    "for c7 in industry_columns[0:9]:\n",
    "    industry.append(c7.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "360ef210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f7c0008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net_Worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Krishna Kumar Bangur</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>61</td>\n",
       "      <td>India</td>\n",
       "      <td>graphite electrodes</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Wilbur 'Ed' Bosarge, Jr.</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>82</td>\n",
       "      <td>United States</td>\n",
       "      <td>high speed trading</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Johanna Braun</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>42</td>\n",
       "      <td>Germany</td>\n",
       "      <td>medical technology</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Karl Friedrich Braun</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>39</td>\n",
       "      <td>Germany</td>\n",
       "      <td>medical technology</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Jean-Pierre Cayard</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>79</td>\n",
       "      <td>France</td>\n",
       "      <td>spirits</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Tony Chen</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>72</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Vivien Chen</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>63</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>real estate</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Chey Ki-won</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>57</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>computer services, telecom</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Pollyanna Chu</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>64</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>financial services, property</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                      Name Net_Worth Age    Citizenship  \\\n",
       "0  2578.      Krishna Kumar Bangur      $1 B  61          India   \n",
       "1  2578.  Wilbur 'Ed' Bosarge, Jr.      $1 B  82  United States   \n",
       "2  2578.             Johanna Braun      $1 B  42        Germany   \n",
       "3  2578.      Karl Friedrich Braun      $1 B  39        Germany   \n",
       "4  2578.        Jean-Pierre Cayard      $1 B  79         France   \n",
       "5  2578.                 Tony Chen      $1 B  72         Taiwan   \n",
       "6  2578.               Vivien Chen      $1 B  63      Hong Kong   \n",
       "7  2578.               Chey Ki-won      $1 B  57    South Korea   \n",
       "8  2578.             Pollyanna Chu      $1 B  64      Hong Kong   \n",
       "\n",
       "                         Source               Industry  \n",
       "0           graphite electrodes          Manufacturing  \n",
       "1            high speed trading  Finance & Investments  \n",
       "2            medical technology             Healthcare  \n",
       "3            medical technology             Healthcare  \n",
       "4                       spirits        Food & Beverage  \n",
       "5                   electronics             Technology  \n",
       "6                   real estate            Real Estate  \n",
       "7    computer services, telecom             Technology  \n",
       "8  financial services, property  Finance & Investments  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "\n",
    "b_df = pd.DataFrame( {  'Rank' : ranks,\n",
    "                        'Name': names,\n",
    "                        'Net_Worth' : networth,\n",
    "                        'Age': ages,\n",
    "                        'Citizenship': citizenship,\n",
    "                        'Source' : source,\n",
    "                        'Industry': industry\n",
    "                     } )\n",
    "b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "285d6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f25ce8",
   "metadata": {},
   "source": [
    "# 9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefd5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Maximizing the automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030286b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/results?search_query=data+science'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb66f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch = driver.find_element(By.XPATH,'//a[@class=\"yt-simple-endpoint style-scope ytd-video-renderer\"]')\n",
    "\n",
    "srch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "635ffa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "\n",
    "comment_tags = driver.find_elements(By.XPATH,'//div[@class=\"style-scope ytd-comment-renderer\"]')\n",
    "\n",
    "for c in comment_tags[0:2]:\n",
    "    comments.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6119d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9f99ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2749070",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57534e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b89de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4755ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42d2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf387d9",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. \n",
    "You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e17b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\BEULAH\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Maximizing the automated chrome window\n",
    "\n",
    "driver.maximize_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
